{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 3134515,
          "sourceType": "datasetVersion",
          "datasetId": 1909705
        }
      ],
      "dockerImageVersionId": 30665,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nihalakshay2004/Fighting-Fabrication-/blob/main/Fighting%20_fabrication_using_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "manjilkarki_deepfake_and_real_images_path = kagglehub.dataset_download('manjilkarki/deepfake-and-real-images')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "yXE9A202dlpy"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "manjilkarki_deepfake_and_real_images_path"
      ],
      "metadata": {
        "id": "KAaAptNEfGYa",
        "outputId": "b9c5aca9-7d7a-4675-b53e-19a285d2c48c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.cache/kagglehub/datasets/manjilkarki/deepfake-and-real-images/versions/1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls /root/.cache/kagglehub/datasets/manjilkarki/deepfake-and-real-images/versions/1/Dataset\n"
      ],
      "metadata": {
        "id": "ShIaXgTpf6gJ",
        "outputId": "77d98d44-40e1-4ada-e912-0e8998fad213",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mTest\u001b[0m/  \u001b[01;34mTrain\u001b[0m/  \u001b[01;34mValidation\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "# from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from tensorflow.keras.callbacks import Callback , ReduceLROnPlateau , ModelCheckpoint, CSVLogger\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "from tensorflow.keras.losses import categorical_crossentropy as logloss\n",
        "from tensorflow.keras.metrics import categorical_accuracy\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "import scipy\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-06T05:08:01.150382Z",
          "iopub.execute_input": "2024-11-06T05:08:01.15099Z",
          "iopub.status.idle": "2024-11-06T05:08:13.844858Z",
          "shell.execute_reply.started": "2024-11-06T05:08:01.150959Z",
          "shell.execute_reply": "2024-11-06T05:08:13.844067Z"
        },
        "trusted": true,
        "id": "HQ8D0Svtdlp0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/root/.cache/kagglehub/datasets/manjilkarki/deepfake-and-real-images/versions/1/Dataset/Train'\n",
        "valid_dir = '/root/.cache/kagglehub/datasets/manjilkarki/deepfake-and-real-images/versions/1/Dataset/Validation'\n",
        "test_dir = '/root/.cache/kagglehub/datasets/manjilkarki/deepfake-and-real-images/versions/1/Dataset/Test'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-06T05:08:13.846546Z",
          "iopub.execute_input": "2024-11-06T05:08:13.847266Z",
          "iopub.status.idle": "2024-11-06T05:08:13.851912Z",
          "shell.execute_reply.started": "2024-11-06T05:08:13.847232Z",
          "shell.execute_reply": "2024-11-06T05:08:13.850838Z"
        },
        "trusted": true,
        "id": "ATdYkLTQdlp1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# View an image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "import os\n",
        "\n",
        "def view_random_image(target_dir, target_class):\n",
        "  target_folder = target_dir + \"/\" + target_class\n",
        "  print(f\"target folder {target_folder}\")\n",
        "  random_image = random.sample(os.listdir(target_folder), 1)\n",
        "  img = mpimg.imread(target_folder + \"/\" + random_image[0])\n",
        "  plt.imshow(img)\n",
        "  plt.title(target_class)\n",
        "  plt.axis(\"off\");\n",
        "\n",
        "  print(f\"Image shape: {img.shape}\") # show the shape of the image\n",
        "\n",
        "  return img\n",
        "\n",
        "# View random image\n",
        "# img = view_random_image(target_dir=train_dir,\n",
        "#                         target_class=\"Real\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-06T05:08:13.853534Z",
          "iopub.execute_input": "2024-11-06T05:08:13.854168Z",
          "iopub.status.idle": "2024-11-06T05:08:13.880889Z",
          "shell.execute_reply.started": "2024-11-06T05:08:13.854134Z",
          "shell.execute_reply": "2024-11-06T05:08:13.88004Z"
        },
        "trusted": true,
        "id": "gD5MBSasdlp1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               batch_size=32,\n",
        "                                               target_size=(224, 224),\n",
        "                                               class_mode=\"binary\",\n",
        "                                               seed=42)\n",
        "\n",
        "valid_data = valid_datagen.flow_from_directory(valid_dir,\n",
        "                                               batch_size=32,\n",
        "                                               target_size=(224, 224),\n",
        "                                               class_mode=\"binary\",\n",
        "                                               seed=42)\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                               batch_size=1,\n",
        "                                               target_size=(224, 224),\n",
        "                                               class_mode=\"binary\",\n",
        "                                               shuffle=False,\n",
        "                                               seed=42)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-06T05:08:13.882824Z",
          "iopub.execute_input": "2024-11-06T05:08:13.883124Z",
          "iopub.status.idle": "2024-11-06T05:11:32.951446Z",
          "shell.execute_reply.started": "2024-11-06T05:08:13.883101Z",
          "shell.execute_reply": "2024-11-06T05:11:32.950675Z"
        },
        "trusted": true,
        "id": "CdEuBycXdlp2",
        "outputId": "9c1af143-7a92-43cf-c03d-cbbe69ed9e17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 140002 images belonging to 2 classes.\n",
            "Found 39428 images belonging to 2 classes.\n",
            "Found 10905 images belonging to 2 classes.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model1- VGG"
      ],
      "metadata": {
        "id": "nUgFTEgKdlp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# End to End TinyVGG Model\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\n",
        "#Create a CNN model (same as Tiny VGG - https://poloclub.github.io/cnn-explainer/)\n",
        "model_1 = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(filters=20,\n",
        "                         kernel_size=3, # can also be (3, 3)\n",
        "                         activation=\"relu\",\n",
        "                         input_shape=(224, 224, 3)), # first layer specifies input shape (height, width, colour channels)\n",
        "  tf.keras.layers.Conv2D(20, 3, activation=\"relu\"),\n",
        "  tf.keras.layers.MaxPool2D(pool_size=2, # pool_size can also be (2, 2)\n",
        "                            padding=\"valid\"), # padding can also be 'same'\n",
        "  tf.keras.layers.Conv2D(20, 3, activation=\"relu\"),\n",
        "  tf.keras.layers.Conv2D(20, 3, activation=\"relu\"), # activation='relu' == tf.keras.layers.Activations(tf.nn.relu)\n",
        "  tf.keras.layers.MaxPool2D(4),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(1, activation=\"sigmoid\") # binary activation output\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_1 = model_1.fit(train_data,\n",
        "                        epochs=5, #5, 8\n",
        "                        steps_per_epoch=128, # 44, 99, 128, 4k XD\n",
        "                        validation_data=valid_data,\n",
        "                        validation_steps=128)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-06T05:11:32.95273Z",
          "iopub.execute_input": "2024-11-06T05:11:32.953022Z",
          "iopub.status.idle": "2024-11-06T05:20:01.524226Z",
          "shell.execute_reply.started": "2024-11-06T05:11:32.952997Z",
          "shell.execute_reply": "2024-11-06T05:20:01.523431Z"
        },
        "trusted": true,
        "id": "7v_pDv9udlp3",
        "outputId": "8754bc7f-6b8d-4e23-eca8-cde7f0349e24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 3s/step - accuracy: 0.5186 - loss: 0.6921 - val_accuracy: 0.5273 - val_loss: 0.7186\n",
            "Epoch 2/5\n",
            "\u001b[1m105/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.5845 - loss: 0.6710"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the model\n",
        "model_1.save(\"VGG_1.h5\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-31T13:22:27.572465Z",
          "iopub.execute_input": "2024-03-31T13:22:27.572827Z",
          "iopub.status.idle": "2024-03-31T13:22:27.665265Z",
          "shell.execute_reply.started": "2024-03-31T13:22:27.5728Z",
          "shell.execute_reply": "2024-03-31T13:22:27.664138Z"
        },
        "id": "mYnHATbydlp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_prep_image(filename, img_shape=224):\n",
        "  # Read in target file (an image)\n",
        "  print(filename)\n",
        "  img = tf.io.read_file(filename)\n",
        "\n",
        "  img = tf.image.decode_image(img, channels=3)\n",
        "  img = tf.image.resize(img, size = [img_shape, img_shape])\n",
        "  img = img/255.\n",
        "  return img\n",
        "\n",
        "# print(test_data[0])\n",
        "\n",
        "# # print(test_data)\n",
        "\n",
        "\n",
        "# pred = model_1.predict(test_data[9000])\n",
        "# ctr = 1 if pred > .50 else 0\n",
        "# print()\n",
        "# pred"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-06T05:20:01.52551Z",
          "iopub.execute_input": "2024-11-06T05:20:01.525794Z",
          "iopub.status.idle": "2024-11-06T05:20:01.531283Z",
          "shell.execute_reply.started": "2024-11-06T05:20:01.525768Z",
          "shell.execute_reply": "2024-11-06T05:20:01.530388Z"
        },
        "trusted": true,
        "id": "AlpYNjnUdlp4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# func to generate different score and confusion matrix from test score.\n",
        "def gen_test_data(model):\n",
        "    # Generate Confusion Matrix\n",
        "    y_pred = model.predict(test_data)\n",
        "    y_test = test_data.classes\n",
        "\n",
        "#     y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "    y_pred_labels = (y_pred > 0.5).astype(np.float32)\n",
        "\n",
        "    confusion_mat = confusion_matrix(y_test, y_pred_labels)\n",
        "    print(confusion_mat)\n",
        "\n",
        "    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_mat, display_labels = [False, True])\n",
        "\n",
        "    cm_display.plot()\n",
        "    plt.show()\n",
        "\n",
        "    # Get AUC, ROC and Precision Score\n",
        "    print(\"ROC AUC Score:\", metrics.roc_auc_score(y_test, y_pred))\n",
        "    print(\"AP Score:\", metrics.average_precision_score(y_test, y_pred))\n",
        "    print()\n",
        "    print(metrics.classification_report(y_test, y_pred_labels))\n",
        "    _, accu = model.evaluate(test_data)\n",
        "    print('Final Test Acccuracy = {:.3f}'.format(accu*100))\n",
        "\n",
        "gen_test_data(model_1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-06T05:20:01.532387Z",
          "iopub.execute_input": "2024-11-06T05:20:01.532701Z",
          "iopub.status.idle": "2024-11-06T05:22:06.559878Z",
          "shell.execute_reply.started": "2024-11-06T05:20:01.532677Z",
          "shell.execute_reply": "2024-11-06T05:22:06.558949Z"
        },
        "trusted": true,
        "id": "dIVxRpeIdlp4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "p1HCCC93dlp4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the model\n",
        "# model_1.save(\"VGG_1.h5\")\n",
        "\n",
        "# def load_and_prep_image(filename, img_shape=224):\n",
        "#   # Read in target file (an image)\n",
        "#   print(filename)\n",
        "#   img = tf.io.read_file(filename)\n",
        "\n",
        "#   img = tf.image.decode_image(img, channels=3)\n",
        "#   img = tf.image.resize(img, size = [img_shape, img_shape])\n",
        "#   img = img/255.\n",
        "#   return img\n",
        "\n",
        "# test_img = load_and_prep_image(f\"{test_dir}/Real/real_4.jpg\")\n",
        "# test_img = tf.expand_dims(test_img, axis=0)\n",
        "\n",
        "import keras\n",
        "model_1.save(\"/kaggle/working/VGG_01_FINAL.keras\")\n",
        "\n",
        "# reconstructed_model = keras.models.load_model(\"/kaggle/working/vgg_01.keras\")\n",
        "\n",
        "# # Let's check:\n",
        "# print(np.testing.assert_allclose(\n",
        "#     model_1.predict(test_img), reconstructed_model.predict(test_img)\n",
        "# ))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-06T05:22:06.561365Z",
          "iopub.execute_input": "2024-11-06T05:22:06.561656Z",
          "iopub.status.idle": "2024-11-06T05:22:06.615032Z",
          "shell.execute_reply.started": "2024-11-06T05:22:06.561631Z",
          "shell.execute_reply": "2024-11-06T05:22:06.614142Z"
        },
        "trusted": true,
        "id": "I7mzbonWdlp4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.models import load_model\n",
        "# vgg_1 = load_model('/kaggle/working/VGG_1.h5')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-06T05:22:06.616016Z",
          "iopub.execute_input": "2024-11-06T05:22:06.616317Z",
          "iopub.status.idle": "2024-11-06T05:22:06.621007Z",
          "shell.execute_reply.started": "2024-11-06T05:22:06.616293Z",
          "shell.execute_reply": "2024-11-06T05:22:06.620118Z"
        },
        "trusted": true,
        "id": "q-ipeXW8dlp4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# def load_and_prep_image(filename, img_shape=224):\n",
        "#   # Read in target file (an image)\n",
        "#   print(filename)\n",
        "#   img = tf.io.read_file(filename)\n",
        "\n",
        "#   img = tf.image.decode_image(img, channels=3)\n",
        "#   img = tf.image.resize(img, size = [img_shape, img_shape])\n",
        "#   img = img/255.\n",
        "#   return img\n",
        "\n",
        "# test_img = load_and_prep_image(f\"{test_dir}/Real/real_4.jpg\")\n",
        "# test_img = tf.expand_dims(test_img, axis=0)\n",
        "# vgg_1.predict(test_img)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-06T05:22:06.624822Z",
          "iopub.execute_input": "2024-11-06T05:22:06.625112Z",
          "iopub.status.idle": "2024-11-06T05:22:06.629842Z",
          "shell.execute_reply.started": "2024-11-06T05:22:06.625069Z",
          "shell.execute_reply": "2024-11-06T05:22:06.628938Z"
        },
        "trusted": true,
        "id": "7zIbmLfzdlp4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# pd.DataFrame(history_1.history).plot(figsize=(10, 7));"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-06T05:22:06.630918Z",
          "iopub.execute_input": "2024-11-06T05:22:06.63127Z",
          "iopub.status.idle": "2024-11-06T05:22:06.644616Z",
          "shell.execute_reply.started": "2024-11-06T05:22:06.631239Z",
          "shell.execute_reply": "2024-11-06T05:22:06.64386Z"
        },
        "trusted": true,
        "id": "gZlS7tFhdlp5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the validation and training data separately\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns separate loss curves for training and validation metrics.\n",
        "  \"\"\"\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "  epochs = range(len(history.history['loss']))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label='training_loss')\n",
        "  plt.plot(epochs, val_loss, label='val_loss')\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
        "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend();"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-06T05:22:06.64554Z",
          "iopub.execute_input": "2024-11-06T05:22:06.645805Z",
          "iopub.status.idle": "2024-11-06T05:22:06.655308Z",
          "shell.execute_reply.started": "2024-11-06T05:22:06.645773Z",
          "shell.execute_reply": "2024-11-06T05:22:06.654416Z"
        },
        "trusted": true,
        "id": "8FwDHpfZdlp5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(history_1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-06T05:22:06.656332Z",
          "iopub.execute_input": "2024-11-06T05:22:06.656586Z",
          "iopub.status.idle": "2024-11-06T05:22:07.308798Z",
          "shell.execute_reply.started": "2024-11-06T05:22:06.656565Z",
          "shell.execute_reply": "2024-11-06T05:22:07.307912Z"
        },
        "trusted": true,
        "id": "o4UYM3-gdlp5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN"
      ],
      "metadata": {
        "id": "U7YGKc50dlp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_2 with a MaxPool2D layer after every Conv2D layer\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model_2 = Sequential([\n",
        "  Conv2D(20, 3, activation='relu', input_shape=(224, 224, 3)),\n",
        "  MaxPool2D(pool_size=2), # reduce number of features by half\n",
        "  Conv2D(20, 3, activation='relu'),\n",
        "  MaxPool2D(),\n",
        "  Conv2D(20, 3, activation='relu'),\n",
        "  MaxPool2D(),\n",
        "  Flatten(),\n",
        "  Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_2.compile(loss='binary_crossentropy',\n",
        "                optimizer=Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "history_2 = model_2.fit(train_data,\n",
        "                        epochs=6,\n",
        "                        steps_per_epoch=256,\n",
        "                        validation_data=valid_data,\n",
        "                        validation_steps=256)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-06T05:22:07.310179Z",
          "iopub.execute_input": "2024-11-06T05:22:07.310551Z",
          "iopub.status.idle": "2024-11-06T05:39:21.636298Z",
          "shell.execute_reply.started": "2024-11-06T05:22:07.310518Z",
          "shell.execute_reply": "2024-11-06T05:39:21.63546Z"
        },
        "trusted": true,
        "id": "lx81zcpCdlp5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(history_2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-06T05:39:21.637872Z",
          "iopub.execute_input": "2024-11-06T05:39:21.638315Z",
          "iopub.status.idle": "2024-11-06T05:39:22.298639Z",
          "shell.execute_reply.started": "2024-11-06T05:39:21.638281Z",
          "shell.execute_reply": "2024-11-06T05:39:22.297742Z"
        },
        "trusted": true,
        "id": "sTSBWsgsdlp5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.save(\"VGG_2_FINAL.h5\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-06T05:39:22.299778Z",
          "iopub.execute_input": "2024-11-06T05:39:22.300053Z",
          "iopub.status.idle": "2024-11-06T05:39:22.331597Z",
          "shell.execute_reply.started": "2024-11-06T05:39:22.300029Z",
          "shell.execute_reply": "2024-11-06T05:39:22.330881Z"
        },
        "trusted": true,
        "id": "STc1JVendlp5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Try DataAugmentation during image preprocessing.\n",
        "gen_test_data(model_2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-06T05:39:22.332584Z",
          "iopub.execute_input": "2024-11-06T05:39:22.332831Z",
          "iopub.status.idle": "2024-11-06T05:40:30.945759Z",
          "shell.execute_reply.started": "2024-11-06T05:39:22.332809Z",
          "shell.execute_reply": "2024-11-06T05:40:30.944909Z"
        },
        "trusted": true,
        "id": "Z8AoDkpkdlp5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# def load_and_prep_image(filename, img_shape=224):\n",
        "#   # Read in target file (an image)\n",
        "#   print(filename)\n",
        "#   img = tf.io.read_file(filename)\n",
        "\n",
        "#   img = tf.image.decode_image(img, channels=3)\n",
        "#   img = tf.image.resize(img, size = [img_shape, img_shape])\n",
        "#   img = img/255.\n",
        "#   return img"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-06T05:40:30.947278Z",
          "iopub.execute_input": "2024-11-06T05:40:30.947568Z",
          "iopub.status.idle": "2024-11-06T05:40:30.951755Z",
          "shell.execute_reply.started": "2024-11-06T05:40:30.947541Z",
          "shell.execute_reply": "2024-11-06T05:40:30.950755Z"
        },
        "trusted": true,
        "id": "A46tXd1Ddlp5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# train_img_path_1 = f\"{test_dir}/Real/real_4.jpg\"\n",
        "# train_img_path_2 = f\"{test_dir}/Fake/fake_12.jpg\"\n",
        "# train_img_real_1 = load_and_prep_image(train_img_path_1)\n",
        "# train_img_real_2 = load_and_prep_image(train_img_path_2)\n",
        "# train_img_real_1 = tf.expand_dims(train_img_real_1, axis=0)\n",
        "# train_img_real_2 = tf.expand_dims(train_img_real_2, axis=0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-06T05:40:30.95283Z",
          "iopub.execute_input": "2024-11-06T05:40:30.953161Z",
          "iopub.status.idle": "2024-11-06T05:40:30.964009Z",
          "shell.execute_reply.started": "2024-11-06T05:40:30.953136Z",
          "shell.execute_reply": "2024-11-06T05:40:30.963144Z"
        },
        "trusted": true,
        "id": "5dt-JMc7dlp6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# pred_1 = model_2.predict(train_img_real_1)\n",
        "# pred_2 = model_2.predict(train_img_real_2)\n",
        "# print(pred_1)\n",
        "# print(pred_2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-06T05:40:30.965225Z",
          "iopub.execute_input": "2024-11-06T05:40:30.96558Z",
          "iopub.status.idle": "2024-11-06T05:40:30.97431Z",
          "shell.execute_reply.started": "2024-11-06T05:40:30.96555Z",
          "shell.execute_reply": "2024-11-06T05:40:30.973394Z"
        },
        "trusted": true,
        "id": "sOi9ZOWadlp6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resnet 50"
      ],
      "metadata": {
        "id": "N56eI13qdlp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=(224,224,3)\n",
        "batch_size=64\n",
        "\n",
        "\n",
        "def build_model():\n",
        "    res_densenet = ResNet50(\n",
        "                        weights='imagenet',\n",
        "                        include_top=False,\n",
        "                        input_shape=input_shape\n",
        "                        )\n",
        "    res_model = Sequential([res_densenet,\n",
        "                        layers.GlobalAveragePooling2D(),\n",
        "                        layers.Dense(64,activation='relu'),\n",
        "                        layers.BatchNormalization(),\n",
        "                        layers.Dropout(0.5),\n",
        "                        layers.Dense(1, activation='sigmoid')\n",
        "                        ])\n",
        "    res_model.compile(optimizer=Adam(),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy']\n",
        "                 )\n",
        "    return res_model\n",
        "\n",
        "\n",
        "model_resnet = build_model()\n",
        "model_resnet.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-06T05:40:30.975706Z",
          "iopub.execute_input": "2024-11-06T05:40:30.975974Z",
          "iopub.status.idle": "2024-11-06T05:40:33.196677Z",
          "shell.execute_reply.started": "2024-11-06T05:40:30.975951Z",
          "shell.execute_reply": "2024-11-06T05:40:33.195827Z"
        },
        "trusted": true,
        "id": "Ub3mcevOdlp6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "history_3 = model_resnet.fit(train_data,\n",
        "    epochs = 8,\n",
        "    steps_per_epoch = 256,\n",
        "    validation_data =valid_data,\n",
        "    validation_steps = 256\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-06T05:40:33.197797Z",
          "iopub.execute_input": "2024-11-06T05:40:33.198082Z",
          "iopub.status.idle": "2024-11-06T06:02:23.766395Z",
          "shell.execute_reply.started": "2024-11-06T05:40:33.198057Z",
          "shell.execute_reply": "2024-11-06T06:02:23.765541Z"
        },
        "trusted": true,
        "id": "bUorY8-Pdlp6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(history_3)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-06T06:02:23.767684Z",
          "iopub.execute_input": "2024-11-06T06:02:23.767989Z",
          "iopub.status.idle": "2024-11-06T06:02:24.415889Z",
          "shell.execute_reply.started": "2024-11-06T06:02:23.767962Z",
          "shell.execute_reply": "2024-11-06T06:02:24.415083Z"
        },
        "trusted": true,
        "id": "kJMDrih_dlp6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet50_1 Save\n",
        "import keras\n",
        "model_resnet.save(\"/kaggle/working/Res_01_FINAL.keras\")\n",
        "\n",
        "# reconstructed_model = keras.models.load_model(\"/kaggle/working/Res_01.keras\")\n",
        "\n",
        "# # Let's check:\n",
        "# np.testing.assert_allclose(\n",
        "#     model.predict(test_input), reconstructed_model.predict(test_input)\n",
        "# )\n",
        "\n",
        "# filename = 'ResNet50_1.pkl'\n",
        "# pickle.dump(model_resnet, open(filename, 'wb'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-06T06:02:24.417149Z",
          "iopub.execute_input": "2024-11-06T06:02:24.417427Z",
          "iopub.status.idle": "2024-11-06T06:02:25.828006Z",
          "shell.execute_reply.started": "2024-11-06T06:02:24.417403Z",
          "shell.execute_reply": "2024-11-06T06:02:25.827003Z"
        },
        "trusted": true,
        "id": "QnAf-rVodlp6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# def load_and_prep_image(filename, img_shape=224):\n",
        "#   # Read in target file (an image)\n",
        "#   print(filename)\n",
        "#   img = tf.io.read_file(filename)\n",
        "\n",
        "#   img = tf.image.decode_image(img, channels=3)\n",
        "#   img = tf.image.resize(img, size = [img_shape, img_shape])\n",
        "#   img = img/255.\n",
        "#   return img\n",
        "\n",
        "# test_img = load_and_prep_image(f\"{test_dir}/Fake/fake_10.jpg\")\n",
        "# test_img = tf.expand_dims(test_img, axis=0)\n",
        "# # vggyo.predict(test_img)\n",
        "# model_resnet.predict(test_img)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-06T06:02:25.829514Z",
          "iopub.execute_input": "2024-11-06T06:02:25.829821Z",
          "iopub.status.idle": "2024-11-06T06:02:25.834459Z",
          "shell.execute_reply.started": "2024-11-06T06:02:25.829794Z",
          "shell.execute_reply": "2024-11-06T06:02:25.833459Z"
        },
        "trusted": true,
        "id": "3d_Kacledlp6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.models import load_model\n",
        "# vggyo = load_model('/kaggle/working/Res_0100.keras')\n",
        "\n",
        "# def load_and_prep_image(filename, img_shape=224):\n",
        "#   # Read in target file (an image)\n",
        "#   print(filename)\n",
        "#   img = tf.io.read_file(filename)\n",
        "\n",
        "#   img = tf.image.decode_image(img, channels=3)\n",
        "#   img = tf.image.resize(img, size = [img_shape, img_shape])\n",
        "#   img = img/255.\n",
        "#   return img\n",
        "\n",
        "# test_img = load_and_prep_image(f\"{test_dir}/Real/real_4.jpg\")\n",
        "# test_img = tf.expand_dims(test_img, axis=0)\n",
        "# vggyo.predict(test_img)\n",
        "\n",
        "gen_test_data(model_resnet)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-06T06:02:25.835638Z",
          "iopub.execute_input": "2024-11-06T06:02:25.835906Z"
        },
        "trusted": true,
        "id": "rPNueLWkdlp6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model_2():\n",
        "    densenet = ResNet50(\n",
        "                        weights='imagenet',\n",
        "                        include_top=False,\n",
        "                        input_shape=input_shape\n",
        "                        )\n",
        "    model = Sequential([densenet,\n",
        "                        layers.GlobalAveragePooling2D(),\n",
        "                        layers.Dense(512,activation='relu'),\n",
        "                        layers.Dense(128,activation='relu'),\n",
        "                        layers.BatchNormalization(),\n",
        "                        layers.Dense(64,activation='relu'),\n",
        "                        layers.BatchNormalization(),\n",
        "                        layers.Dense(64,activation='relu'),\n",
        "                        layers.BatchNormalization(),\n",
        "                        layers.Dropout(0.5),\n",
        "                        layers.Dense(128,activation='relu'),\n",
        "                        layers.Flatten(),\n",
        "                        layers.Dense(128,activation='relu'),\n",
        "                        layers.Dense(1, activation='sigmoid')\n",
        "                        ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy']\n",
        "                 )\n",
        "    return model\n",
        "\n",
        "\n",
        "model_resnet_2 = build_model_2()\n",
        "model_resnet_2.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "f6y3_-HRdlp6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "history_4 = model_resnet_2.fit(train_data,\n",
        "    epochs = 16,\n",
        "    steps_per_epoch = 128,\n",
        "    validation_data =valid_data,\n",
        "    validation_steps = 126\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "y4OkL4Pjdlp7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(history_4)"
      ],
      "metadata": {
        "trusted": true,
        "id": "OqgfzQ09dlp7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "gen_test_data(model_resnet_2)"
      ],
      "metadata": {
        "trusted": true,
        "id": "EA97XA8Pdlp7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet50_1 Save\n",
        "import keras\n",
        "model_resnet_2.save(\"/kaggle/working/Res_02_FINAL.keras\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "2od8odXhdlp7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet50_2 Save\n",
        "\n",
        "# model_resnet_2.save(\"ResNet50_2.h5\")\n",
        "\n",
        "# tf.random.set_seed(42)\n",
        "# history_resnet_2 = model_resnet_2.fit(train_data,\n",
        "#     epochs = 6,\n",
        "#     steps_per_epoch = 1024,\n",
        "#     validation_data =valid_data,\n",
        "#     validation_steps = 1024\n",
        "# )\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "6H49up5Odlp7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2txn6K8Idlp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot_loss_curves(history_resnet_2)"
      ],
      "metadata": {
        "trusted": true,
        "id": "q55oWAoydlp-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# InceptionNet"
      ],
      "metadata": {
        "id": "OHlVjOz4dlp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "input_shape=(224,224,3)\n",
        "batch_size=64\n",
        "\n",
        "def build_model_inception():\n",
        "    densenet = InceptionV3(\n",
        "                        weights='imagenet',\n",
        "                        include_top=False,\n",
        "                        input_shape=input_shape,\n",
        "                        )\n",
        "    model = Sequential([densenet,\n",
        "                        layers.GlobalAveragePooling2D(),\n",
        "                        layers.Dense(512,activation='relu'),\n",
        "                        layers.BatchNormalization(),\n",
        "                        layers.Dense(256,activation='relu'),\n",
        "                        layers.BatchNormalization(),\n",
        "                        layers.Dense(128,activation='relu'),\n",
        "                        layers.BatchNormalization(),\n",
        "                        layers.Dropout(0.5),\n",
        "                        layers.Dense(1, activation='sigmoid')\n",
        "                        ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy']\n",
        "                 )\n",
        "    return model\n",
        "\n",
        "model_icv3 = build_model_inception()\n",
        "model_icv3.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "UMj4sEyCdlp-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "history_5 = model_icv3.fit(train_data,\n",
        "    epochs = 8,\n",
        "    steps_per_epoch = 1024,\n",
        "    validation_data =valid_data,\n",
        "    validation_steps = 1024\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "6OStP_0jdlp_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(history_5)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Aij0RHo-dlp_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# InceptionNetV3_1 Save\n",
        "# ResNet50_1 Save\n",
        "import keras\n",
        "model_icv3.save(\"/kaggle/working/ICV3_FINAL.keras\")\n",
        "\n",
        "\n",
        "# filename = 'InceptionNetV3_1.pkl'\n",
        "# pickle.dump(model_icv3, open(filename, 'wb'))"
      ],
      "metadata": {
        "trusted": true,
        "id": "8Xok5Gazdlp_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.random.set_seed(42)\n",
        "# history_icv3_2 = model_icv3.fit(train_data,\n",
        "#     epochs = 24,\n",
        "#     steps_per_epoch = 1024,\n",
        "#     validation_data =valid_data,\n",
        "#     validation_steps = 1024\n",
        "# )\n",
        "\n",
        "gen_test_data(model_icv3)"
      ],
      "metadata": {
        "trusted": true,
        "id": "QYAsQ_O7dlp_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# plot_loss_curves(history_icv3_2)"
      ],
      "metadata": {
        "trusted": true,
        "id": "dyCYglD2dlp_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "Tp87jsJcdlp_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "zuw0O96Kdlp_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a dictionary to store losses\n",
        "model_losses = {}\n",
        "\n",
        "# Fit models and store the losses\n",
        "\n",
        "model_losses['model1'] = history_1.history['loss']\n",
        "\n",
        "\n",
        "model_losses['model2'] = history_2.history['loss']\n",
        "\n",
        "\n",
        "model_losses['model3'] = history_3.history['loss']\n",
        "\n",
        "model_losses['model4'] = history_4.history['loss']\n",
        "\n",
        "model_losses['model5'] = history_5.history['loss']\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "trLekwvVdlp_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_losses"
      ],
      "metadata": {
        "trusted": true,
        "id": "ExGiYUfndlp_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "AGGqulJCdlp_"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}